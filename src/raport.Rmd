---
output:
  pdf_document: default
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dendextend)
library(mclust)
library(ggplot2)
library(gridExtra)
set.seed(100)
```

# Wstęp
Analiza skupień jest zadaniem eksploracji i etykietowania danych, które polega na dzieleniu zbioru danych na grupy (skupienia) tak, by elementy w jednej grupie były do siebie jak najbardziej podobne, a jednocześnie jak najbardziej odmienne od elementów z pozostałych grup. Jako że analiza skupień znalazła swoje zastosowanie w wielu dziedzinach nauki, dostępna jest mnogość bibliotek, które implementują ten algorytm. Zajmiemy się poniższymi:

* algorytmy hierarchiczne `hlcust` dostępne w bazowym R,
* algorytmem Genie,
* algorytmem `specc` z pakietu `kernlab`,
* autorską implementacją analizy skupień.

Interesujące może się wydawać porównanie dostępnych implementacji i wybranie tej najlepszej. Czy jest to jednak wybór oczywisty? Czy wydajność i dokładność algorytmów zależy od zbioru danych? W odpowiedzi na te pytania pomogą wskaźniki FM i AR, które jednoznacznie porównają wyniki zwracane przez algorytmy dla zbiorów benchmarkowych z wzorcowymi. Zarówno **skorygowany indeks Randa**, jak i **indeks Fowlkesa–Mallowsa** pozwalają ocenić zgodność dwóch podziałów zbioru na rozłączne podzbiory. Ponadto, AR uwzględnia prawdopodobieństwo, że dwa algorytmy grupowania zachowując się losowo, równocześnie rozdzielą parę lub dołączą do jednej grupy.


# Własna implementacja analizy skupień
```r
function(X, k, M) {
    S <- Mnn(X, M);
    G <- Mnn_graph(S);
    D <- Mnn_graph_D_matrix(G);
    G <- Mnn_connect_graph(G);
    E <- Laplacian_eigen(D, G, k);
    set.seed(100);
    return(kmeans(E, k));
}
```
Autorska implementacja algorytmu jest pewnego rodzaju heurystyką - na początku ma na celu znormalizowanie danych, a potem zasotowanie bazowego algorytmu k-średnich. Normalizacja jest oparta na trzech najważniejszych krokach:

1. **Wyznaczenie macierzy najbliższych sąsiadów.**

Na początku algorytm wyznacza macierz najbliższych sąsiadów, wywołując `Mnn`. Kod tej funkcji jest napisany w języku C++. Wyznaczanie najbliższych sąsiadów odbywa się z wykorzystaniem `priority_queue` dla lepszej złożoności zamortyzowanej.

2. **Wyznaczenie macierzy sąsiedztwa.**

Następnie funkcja `Mnn_graph` generuje symetryczną macierz sąsiedztwa dla pewnego grafu. Potem, funkcja `Mnn_graph_D_matrix` tworzy macierz diagonalną reprezentującą stopnie w grafie. Po stworzeniu macierzy, wywołanie `Mnn_connect_graph` łączy spójne składowe grafu i zapisuje te zmiany do macierzy sąsziedztwa. Spójne składowe są wyznaczane, przechodząc po grafie algorytmem przeszukiwania w głąb (DFS). Łączone są wierzchołki wyznaczone jako pierwsze dla każdej składowej podczas przeszukiwania.

3. **Wyznaczanie laplasjanu i jego wektorów własnych.**

Ostatnim etapem algorytmu jest wyznaczenie laplasjanu grafu, którego składowe jeszcze nie zostały połączone. Finalnie, wyznaczane są wartości własne wyznaczonego laplasjanu. Wyznacznie ich przy użyciu bazowej funkcji `base::eigen` było bardzo nieefektywne, nawet przy poinformowaniu funkcji o symetryczności macierzy. Zamiast tego wykorzystana została funkcja `RSpectra::eigs_sym`, która wykonywała się znacząco szybciej dla wszystkich zbiorów benchmarkowych.

# Indeksy FM i AR dla bazowych algorytmów hierarchicznych

```{r echo=FALSE, fig.height=7, fig.align='center'}
    Compare_hclust_methods <- function(fileName) {
        setsPath <- "D:/Studia/_PrzetwarzanieDanych/praca_domowa2/zbiory-benchmarkowe";
        setwd(setsPath);
        data <- read.table(paste0(fileName, ".data.gz"));
        labels <- as.integer(read.table(paste0(fileName, ".labels0.gz"))[,1]);
        k <- max(labels);
        
        # Process algorithms
        resultsFolder <- paste0(setsPath, "/results/hclust_")
        hCompleteResult <- read.table(paste0(resultsFolder, "complete", "/", fileName, ".csv"));
        hSingleResult <- read.table(paste0(resultsFolder, "single", "/", fileName, ".csv"));
        hAverageResult <- read.table(paste0(resultsFolder, "average", "/", fileName, ".csv"));
        hWardResult <- read.table(paste0(resultsFolder, "ward.D2", "/", fileName, ".csv"));
        hMcquittyResult <- read.table(paste0(resultsFolder, "mcquitty", "/", fileName, ".csv"));
        hMedianResult <- read.table(paste0(resultsFolder, "median", "/", fileName, ".csv"));
        hCentroidResult <- read.table(paste0(resultsFolder, "centroid", "/", fileName, ".csv"));
         
        # Find similarity indices
        dt <- data.frame("Method" = "Complete", "Index" = "FM", "Value" = FM_index(hCompleteResult, labels)[1], stringsAsFactors = FALSE);
        dt[nrow(dt) + 1,] = list("Complete", "AR", adjustedRandIndex(hCompleteResult, labels));
        dt[nrow(dt) + 1,] = list("Single", "FM", FM_index(hSingleResult, labels)[1]);
        dt[nrow(dt) + 1,] = list("Single", "AR", adjustedRandIndex(hSingleResult, labels));
        dt[nrow(dt) + 1,] = list("Average", "FM", FM_index(hAverageResult, labels)[1]);
        dt[nrow(dt) + 1,] = list("Average", "AR", adjustedRandIndex(hAverageResult, labels));
        dt[nrow(dt) + 1,] = list("ward.D2", "FM", FM_index(hWardResult, labels)[1]);
        dt[nrow(dt) + 1,] = list("ward.D2", "AR", adjustedRandIndex(hWardResult, labels));
        dt[nrow(dt) + 1,] = list("mcquitty", "FM", FM_index(hMcquittyResult, labels)[1]);
        dt[nrow(dt) + 1,] = list("mcquitty", "AR", adjustedRandIndex(hMcquittyResult, labels));
        dt[nrow(dt) + 1,] = list("median", "FM", FM_index(hMedianResult, labels)[1]);
        dt[nrow(dt) + 1,] = list("median", "AR", adjustedRandIndex(hMedianResult, labels));
        dt[nrow(dt) + 1,] = list("centroid", "FM", FM_index(hCentroidResult, labels)[1]);
        dt[nrow(dt) + 1,] = list("centroid", "AR", adjustedRandIndex(hCentroidResult, labels));
        return(dt);
    }


    benchmarkSets <- c("cross", "dense", "lsun")
    hclustResult <- lapply(benchmarkSets, Compare_hclust_methods)
    
    getPlot <- function(hclustResult, index, benchmarkSets) {
        return(ggplot(hclustResult[[index]], aes(factor(Method), Value, fill = Index)) + 
        geom_bar(stat="identity", position = "dodge") +  
        ggtitle(paste("Set name", benchmarkSets[index])) +
        scale_fill_brewer(palette = "Set1") + 
        theme(axis.text.x=element_text(angle=20, hjust=1), axis.title.x=element_blank()) +
        geom_text(aes(label = round(Value, digits = 2)), position=position_dodge(width=0.9), vjust=-0.25, size=2) + ylab("Wartość wskaźnika"))
    }
    
    p1 <- getPlot(hclustResult, 1, benchmarkSets)
    p2 <- getPlot(hclustResult, 2, benchmarkSets)
    p3 <- getPlot(hclustResult, 3, benchmarkSets)
    
    grid.arrange(p1, p2, p3, nrow=3)
```

# Indeksy FM i AR dla algorytmu Genie

```{r echo=FALSE, fig.height=3.4, fig.align='center'}
    Compare_genie_method <- function(fileName) {
        setsPath <- "D:/Studia/_PrzetwarzanieDanych/praca_domowa2/zbiory-benchmarkowe";
        setwd(setsPath);
        labels <- as.integer(read.table(paste0(fileName, ".labels0.gz"))[,1]);
        
        genieResult <- read.table(paste0(setsPath, "/results/genie/", fileName, ".csv"));
        
        dt <- data.frame("Set name" = fileName, "Index" = "FM", "Value" = FM_index(genieResult, labels)[1], stringsAsFactors = FALSE);
        dt[nrow(dt) + 1,] = list(fileName, "AR", adjustedRandIndex(genieResult, labels));
        
        return(dt)
    }
    
    benchmarkSets <- c("cross", "dense", "lsun", "spiral", "wingnut", "zigzag");
    genieResults <- lapply(benchmarkSets, Compare_genie_method);
    df <- Reduce(rbind, genieResults);
    ggplot(df, aes(factor(Set.name), Value, fill = Index)) + 
        geom_bar(stat="identity", position = "dodge") +  
        scale_fill_brewer(palette = "Set1") + 
        geom_text(aes(label = round(Value, digits = 2)), position=position_dodge(width=0.9), vjust=-0.25, size=2) + xlab("Zbiór") + ylab("Wartość wskaźnika")
```

# Indeksy FM i AR dla funkcji specc w pakiecie kernlab
Pakiet `kernlab`, dostępny na [CRAN](https://www.rdocumentation.org/packages/kernlab/versions/0.9-27), udostępnia funkcję `specc`, która dokonuje analizy skupień na zadanym zbiorze danych. Zgodnie ze specyfikacją, algorytm osadza przetwarzane punkty w przestrzeni k największych wartości własnych znormlizowanej macierzy podobieństwa.

> Spectral clustering works by embedding the data points of the partitioning problem into the subspace of the k largest eigenvectors of a normalized affinity/kernel matrix.

Poniżej zestawienie wyników działania algorytmu dla przykładowych zbiorów benchmarkowych.

```{r fig.width=6, fig.height=3.4, echo=FALSE, fig.align='center'}
    # Wartosci hardcodowane ze wzgledu na dlugi czas przetwarzania
    kernlabResults <- structure(list(Set.name = c("cross", "cross", "dense", "dense", 
        "lsun", "lsun", "spiral", "spiral", "wingnut", "wingnut", "zigzag", 
        "zigzag"), Index = c("FM", "AR", "FM", "AR", "FM", "AR", "FM", 
        "AR", "FM", "AR", "FM", "AR"), Value = c(0.465340930201732, 0.105087003417032, 
        0.694993439169809, 0.2603194214965435, 1, 1, 1, 1, 1, 1, 1, 
        1)), class = "data.frame")

    ggplot(kernlabResults, aes(factor(Set.name), Value, fill = Index)) + 
        geom_bar(stat="identity", position = "dodge") +  
        scale_fill_brewer(palette = "Set1") + 
        geom_text(aes(label = round(Value, digits = 2)), position=position_dodge(width=0.9), vjust=-0.25, size=2) + xlab("Zbiór") + ylab("Wartość wskaźnika")
```

Jak widać, `kernlab:specc` osiąga pełną zgodność z wzorcowymi skupieniami dla niektórych zbiorów (po głębszej analize - zadowalające wyniki dla 26/44 zbiorów). Minusem opisywanego algorytmu jest jego szybkość działania - średnia szybkość wykonania analizy to 7 sekund.

# Indeksy FM i AR dla własnej implementacji algorytmu 


# Wnioski
